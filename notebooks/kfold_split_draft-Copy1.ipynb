{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b334baae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "PyTorch Version:  2.0.0\n",
      "Torchvision Version:  0.15.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models  import resnet101, ResNet101_Weights\n",
    "from torchvision import models\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Resize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "# from torchsummary import summary\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633dcc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(31101995)\n",
    "torch.manual_seed(31101995)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "# Set seed\n",
    "seed_everything(31101995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c7bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_csv_path = '/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/meta_data_survival_mapping.csv'\n",
    "\n",
    "class_column_name = 'label_flair'\n",
    "subject_id_column_name = 'subject_id'\n",
    "\n",
    "healthy = 'healthy'\n",
    "discard = 'discard'\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(meta_csv_path)\n",
    "del df_meta['Brats20ID']\n",
    "del df_meta['Age']\n",
    "del df_meta['Survival_days']\n",
    "del df_meta['Extent_of_Resection']\n",
    "df_meta\n",
    "\n",
    "def remove_columns(meta_csv_path):    \n",
    "    df_meta = pd.read_csv(meta_csv_path)\n",
    "    del df_meta['Brats20ID']\n",
    "    del df_meta['Age']\n",
    "    del df_meta['Survival_days']\n",
    "    del df_meta['Extent_of_Resection']\n",
    "    return df_meta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ebc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(df_meta.groupby(['subject_id'])['label_flair'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_label_dict(df, class_column):\n",
    "    class_dict = df[class_column].value_counts().to_dict()\n",
    "    return class_dict\n",
    "\n",
    "class_dict = get_class_label_dict(df_meta, class_column_name)\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca716b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minority_class_values(df_meta, class_dict, \n",
    "                              subject_id_column_name, \n",
    "                              class_column_name):\n",
    "    \n",
    "    samples_per_subject = max(df_meta.groupby([subject_id_column_name])[class_column_name].count())\n",
    "    print('samples_per_subject:', samples_per_subject)\n",
    "    \n",
    "    minority_samples = min(class_dict.values())\n",
    "    minority_class = [k for k, v in class_dict.items() if v == minority_samples]\n",
    "    minority_class = minority_class[0]\n",
    "    print('minority_class:',minority_class)\n",
    "\n",
    "    return minority_class, samples_per_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_subject = max(df_meta.groupby([subject_id_column_name])[class_column_name].count())#155\n",
    "print('samples_per_subject:', samples_per_subject)\n",
    "minority_samples = min(class_dict.values())\n",
    "minority_class = [k for k, v in class_dict.items() if v == minority_samples]\n",
    "minority_class = minority_class[0]\n",
    "print('minority_class:',minority_class)\n",
    "\n",
    "# df = df_meta.copy()\n",
    "\n",
    "healthy = 'healthy'\n",
    "discard = 'discard'\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEPS:\n",
    "#1.Get max number od samples/images per subject (=155)\n",
    "#2.Find the minority class_label\n",
    "#3.Set test_size : \n",
    "    #a. 30% minority class\n",
    "    #b. get number of samples in 30% of minority class\n",
    "    #c. get same number of samples from all other classes\n",
    "    # therefore, 30% of minority_class_samples = number of samples per class in test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea178603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minority_class_train_test_split(df_meta, class_dict,\n",
    "                                  minority_class,test_size,\n",
    "                                  subject_id_column_name):\n",
    "    \n",
    "    df = df_meta.copy()\n",
    "    for key in class_dict:\n",
    "        if key == minority_class:\n",
    "            df_class =  df[df[class_column_name] == key]\n",
    "            subject_id_list =  np.unique(df_class[subject_id_column_name]).tolist()\n",
    "            \n",
    "            train_subjects_minority, test_subjects_minority = train_test_split(subject_id_list ,\n",
    "                                            test_size = test_size, \n",
    "                                            random_state = 42, \n",
    "                                            shuffle = True)\n",
    "            \n",
    "    print(len(train_subjects_minority), len(test_subjects_minority))\n",
    "    return train_subjects_minority, test_subjects_minority\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcff404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_meta.copy()\n",
    "\n",
    "for key in class_dict:\n",
    "    if key==minority_class:\n",
    "#         print(key)\n",
    "        df_class =  df[df[class_column_name] == key]\n",
    "        subject_id_list =  np.unique(df_class[subject_id_column_name]).tolist()\n",
    "        \n",
    "        train_subjects_minority, test_subjects_minority = train_test_split(subject_id_list ,\n",
    "                                            test_size = test_size, \n",
    "                                            random_state = 42, \n",
    "                                            shuffle = True)\n",
    "        \n",
    "        \n",
    "df_class['subject_id'].value_counts()\n",
    "print(len(subject_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_subjects_minority), len(test_subjects_minority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_class_train_test_split(df_meta, class_dict,\n",
    "                                        minority_class, healthy,\n",
    "                                        discard, class_column_name,\n",
    "                                        subject_id_column_name,\n",
    "                                        test_subjects_minority):\n",
    "    \n",
    "    train_subjects_other = []\n",
    "    test_subjects_other = []\n",
    "    df = df_meta.copy()\n",
    "    \n",
    "    for key in class_dict:\n",
    "        if key!=healthy and key!=discard and key!=minority_class:            \n",
    "            df_class_majority =  df[df[class_column_name] == key]\n",
    "            subject_id_class =  np.unique(df_class_majority[subject_id_column_name]).tolist()            \n",
    "            test_subjects = random.sample(subject_id_class, len(test_subjects_minority))            \n",
    "            train_subjects = list(set(subject_id_class) - set(test_subjects))            \n",
    "            train_subjects_other.append(train_subjects)\n",
    "            test_subjects_other.append(test_subjects)\n",
    "    \n",
    "    return train_subjects_other, test_subjects_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a5eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_subjects_other = []\n",
    "test_subjects_other = []\n",
    "\n",
    "for key in class_dict:\n",
    "    if key!=healthy and key!=discard and key!=minority_class:\n",
    "        print(key)\n",
    "        df_class_majority =  df[df[class_column_name] == key]\n",
    "        subject_id_class =  np.unique(df_class_majority[subject_id_column_name]).tolist()\n",
    "#         print(random.sample(subject_id_class, len(test_subjects_minority)))\n",
    "        test_subjects = random.sample(subject_id_class, len(test_subjects_minority))\n",
    "    \n",
    "        train_subjects = list(set(subject_id_class) - set(test_subjects))\n",
    "        \n",
    "        train_subjects_other.extend(train_subjects)\n",
    "        test_subjects_other.extend(test_subjects)\n",
    "        \n",
    "        \n",
    "#         print(test_subjects)\n",
    "#         print('train:',train_subjects)\n",
    "        print(len(test_subjects))\n",
    "        print(len(subject_id_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906fe56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ca9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_train_test_split(train_subjects_other, test_subjects_other,\n",
    "                                train_subjects_minority, test_subjects_minority):\n",
    "    \n",
    "    df = get_csv_after_discard(meta_csv_path)\n",
    "    training_subjects_list, test_subjects_list = generate_subject_id_splits(df,\n",
    "                                                                          class_column, \n",
    "                                                                          test_size, \n",
    "                                                                          subject_id_column_name, \n",
    "                                                                          class_healthy_name)\n",
    "    train_df = df[df[subject_id_column_name].isin(training_subjects_list)].reset_index(drop=True)\n",
    "    test_df = df[df[subject_id_column_name].isin(test_subjects_list)].reset_index(drop=True)\n",
    "    \n",
    "    train_df.to_csv(csv_save_path / 'train_df.csv')\n",
    "    test_df.to_csv(csv_save_path / 'test_df.csv')\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932285c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "class_column_name = 'label_flair'\n",
    "subject_id_column_name = 'subject_id'\n",
    "\n",
    "healthy = 'healthy'\n",
    "discard = 'discard'\n",
    "test_size = 0.3\n",
    "\n",
    "def class_to_idx(label):\n",
    "    idx = 0\n",
    "    if label == 'discard':idx =4\n",
    "    if label == 'healthy':idx =0\n",
    "    if label == 'HGG':idx =1\n",
    "    if label=='LGG': idx = 2        \n",
    "    return idx\n",
    "\n",
    "def idx_to_class(idx):\n",
    "    \n",
    "    if idx == 4:label='discard'\n",
    "    if idx == 0:label='healthy'\n",
    "    if idx == 1:label='HGG'\n",
    "    if idx == 2:label='LGG'      \n",
    "    return label\n",
    "\n",
    "\n",
    "def get_metadata_csv_label_encoded(meta_data_df):\n",
    "    \"\"\"Load meta csv. Filter samples to be discarded and label encoding.\"\"\"\n",
    "    meta_data = meta_data_df.copy()\n",
    "    meta_data['label_flair'] = meta_data['label_flair'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t1'] = meta_data['label_t1'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t1ce'] = meta_data['label_t1ce'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t2'] = meta_data['label_t2'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data_df  = meta_data.reset_index(drop =True)\n",
    "    return meta_data_df\n",
    "\n",
    "\n",
    "def create_StratifiedGroupKFold_splits(k, train_df, subject_id_column_name): \n",
    "    \n",
    "    train_df_encoded = get_metadata_csv_label_encoded(train_df)\n",
    "    train_df_encoded['patient_id'] = train_df_encoded[subject_id_column_name].str[-3:].astype(int)\n",
    "    \n",
    "    kfold_dict = {f\"train_{i}\": [] for i in range(k)}\n",
    "    kfold_dict.update({f\"val_{i}\": [] for i in range(k)})\n",
    "    \n",
    "    kfold_dist_dict = {f\"train_{i}\": [] for i in range(k)}\n",
    "    kfold_dist_dict.update({f\"val_{i}\": [] for i in range(k)})\n",
    "\n",
    "    n_splits = k\n",
    "    # Initialize StratifiedGroupKFold\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    # Extract features and target\n",
    "    X = train_df_encoded\n",
    "    y = train_df_encoded['label_flair']\n",
    "    # Define the groups (subject_id in your case)\n",
    "    groups = train_df_encoded['patient_id']\n",
    "    \n",
    "    \n",
    "    # Iterate through the splits\n",
    "    for i, (train_index, val_index) in enumerate(sgkf.split(X, y,groups)):\n",
    "        print(f\"Fold {i}:\")\n",
    "#     for train_idx, val_idx in sgkf.split(X, y, groups=groups):\n",
    "        # Ensure that the validation set is balanced\n",
    "        unique_classes, class_counts = np.unique(y[val_idx], return_counts=True)\n",
    "        min_class_count = min(class_counts)\n",
    "\n",
    "        balanced_val_indices = []\n",
    "        for cls in unique_classes:\n",
    "            cls_indices = val_idx[y[val_idx] == cls]\n",
    "            balanced_val_indices.extend(cls_indices[:min_class_count])\n",
    "\n",
    "#         train_indices.append(train_idx)\n",
    "#         val_indices.append(balanced_val_indices)\n",
    "#         kfold_dict[f'train_{i}'].extend(groups[train_index])\n",
    "        kfold_dict[f'val_{i}'].extend(balanced_val_indices)\n",
    "        kfold_dict[f'train_{i}'].extend(train_index)\n",
    "\n",
    "        kfold_dist_dict[f'val_{i}'] = dict(y[balanced_val_indices].value_counts())\n",
    "        kfold_dist_dict[f'train_{i}'] = dict(y[train_index].value_counts())\n",
    "        \n",
    "#         train_dist =dict( y[train_index].value_counts())\n",
    "#         val_dist =dict( y[balanced_val_indices].value_counts())\n",
    "        # If you want to see the class distribution in each fold\n",
    "        print(f'Fold {len(train_indices)} Class Distribution:')\n",
    "        print(y[balanced_val_indices].value_counts())\n",
    "    return kfold_dict, kfold_dist_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602115e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a5bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5468468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/train_test_splits/test_df.csv',index_col =0)\n",
    "# test_df[test_df['subject_id']== 'BraTS20_Training_212']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924f353c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>image_idx</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_flair</th>\n",
       "      <th>label_t1</th>\n",
       "      <th>label_t1ce</th>\n",
       "      <th>label_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_10</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_100</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_101</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_102</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_103</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44588</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_95</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44589</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_96</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44590</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_97</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44591</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_98</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44592</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_99</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44593 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id                     image_idx  \\\n",
       "0      BraTS20_Training_001   BraTS20_Training_001_seg_10   \n",
       "1      BraTS20_Training_001  BraTS20_Training_001_seg_100   \n",
       "2      BraTS20_Training_001  BraTS20_Training_001_seg_101   \n",
       "3      BraTS20_Training_001  BraTS20_Training_001_seg_102   \n",
       "4      BraTS20_Training_001  BraTS20_Training_001_seg_103   \n",
       "...                     ...                           ...   \n",
       "44588  BraTS20_Training_369   BraTS20_Training_369_seg_95   \n",
       "44589  BraTS20_Training_369   BraTS20_Training_369_seg_96   \n",
       "44590  BraTS20_Training_369   BraTS20_Training_369_seg_97   \n",
       "44591  BraTS20_Training_369   BraTS20_Training_369_seg_98   \n",
       "44592  BraTS20_Training_369   BraTS20_Training_369_seg_99   \n",
       "\n",
       "                                              image_path label_flair label_t1  \\\n",
       "0      /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "1      /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "2      /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "3      /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "4      /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "...                                                  ...         ...      ...   \n",
       "44588  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "44589  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "44590  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "44591  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "44592  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "\n",
       "      label_t1ce label_t2  \n",
       "0        healthy  healthy  \n",
       "1            HGG      HGG  \n",
       "2            HGG      HGG  \n",
       "3            HGG      HGG  \n",
       "4            HGG      HGG  \n",
       "...          ...      ...  \n",
       "44588        HGG      HGG  \n",
       "44589        HGG      HGG  \n",
       "44590        HGG      HGG  \n",
       "44591        HGG      HGG  \n",
       "44592        HGG      HGG  \n",
       "\n",
       "[44593 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_df[train_df['label_flair']!= 'discard'].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36d832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>image_idx</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_flair</th>\n",
       "      <th>label_t1</th>\n",
       "      <th>label_t1ce</th>\n",
       "      <th>label_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BraTS20_Training_011</td>\n",
       "      <td>BraTS20_Training_011_seg_0</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BraTS20_Training_011</td>\n",
       "      <td>BraTS20_Training_011_seg_1</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BraTS20_Training_011</td>\n",
       "      <td>BraTS20_Training_011_seg_10</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BraTS20_Training_011</td>\n",
       "      <td>BraTS20_Training_011_seg_100</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BraTS20_Training_011</td>\n",
       "      <td>BraTS20_Training_011_seg_101</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7125</th>\n",
       "      <td>BraTS20_Training_365</td>\n",
       "      <td>BraTS20_Training_365_seg_95</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>BraTS20_Training_365</td>\n",
       "      <td>BraTS20_Training_365_seg_96</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7127</th>\n",
       "      <td>BraTS20_Training_365</td>\n",
       "      <td>BraTS20_Training_365_seg_97</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>BraTS20_Training_365</td>\n",
       "      <td>BraTS20_Training_365_seg_98</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>BraTS20_Training_365</td>\n",
       "      <td>BraTS20_Training_365_seg_99</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6306 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                subject_id                     image_idx  \\\n",
       "0     BraTS20_Training_011    BraTS20_Training_011_seg_0   \n",
       "1     BraTS20_Training_011    BraTS20_Training_011_seg_1   \n",
       "2     BraTS20_Training_011   BraTS20_Training_011_seg_10   \n",
       "3     BraTS20_Training_011  BraTS20_Training_011_seg_100   \n",
       "4     BraTS20_Training_011  BraTS20_Training_011_seg_101   \n",
       "...                    ...                           ...   \n",
       "7125  BraTS20_Training_365   BraTS20_Training_365_seg_95   \n",
       "7126  BraTS20_Training_365   BraTS20_Training_365_seg_96   \n",
       "7127  BraTS20_Training_365   BraTS20_Training_365_seg_97   \n",
       "7128  BraTS20_Training_365   BraTS20_Training_365_seg_98   \n",
       "7129  BraTS20_Training_365   BraTS20_Training_365_seg_99   \n",
       "\n",
       "                                             image_path label_flair label_t1  \\\n",
       "0     /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "1     /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "2     /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "3     /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "4     /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "...                                                 ...         ...      ...   \n",
       "7125  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "7126  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "7127  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "7128  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "7129  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "\n",
       "     label_t1ce label_t2  \n",
       "0       healthy  healthy  \n",
       "1       healthy  healthy  \n",
       "2       healthy  healthy  \n",
       "3           HGG      HGG  \n",
       "4           HGG      HGG  \n",
       "...         ...      ...  \n",
       "7125        HGG      HGG  \n",
       "7126        HGG      HGG  \n",
       "7127        HGG      HGG  \n",
       "7128        HGG      HGG  \n",
       "7129        HGG      HGG  \n",
       "\n",
       "[6306 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/train_test_splits/test_df.csv',index_col =0)\n",
    "test_df = test_df[test_df['label_flair'] != 'discard']\n",
    "# .reset_index(drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1bdc2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df['label_flair']=='LGG']['subject_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec47d504",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>image_idx</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_flair</th>\n",
       "      <th>label_t1</th>\n",
       "      <th>label_t1ce</th>\n",
       "      <th>label_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_0</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>discard</td>\n",
       "      <td>discard</td>\n",
       "      <td>discard</td>\n",
       "      <td>discard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_1</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>discard</td>\n",
       "      <td>discard</td>\n",
       "      <td>discard</td>\n",
       "      <td>discard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_10</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_100</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BraTS20_Training_001</td>\n",
       "      <td>BraTS20_Training_001_seg_101</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50060</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_95</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50061</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_96</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50062</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_97</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50063</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_98</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50064</th>\n",
       "      <td>BraTS20_Training_369</td>\n",
       "      <td>BraTS20_Training_369_seg_99</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "      <td>HGG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50065 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id                     image_idx  \\\n",
       "0      BraTS20_Training_001    BraTS20_Training_001_seg_0   \n",
       "1      BraTS20_Training_001    BraTS20_Training_001_seg_1   \n",
       "2      BraTS20_Training_001   BraTS20_Training_001_seg_10   \n",
       "3      BraTS20_Training_001  BraTS20_Training_001_seg_100   \n",
       "4      BraTS20_Training_001  BraTS20_Training_001_seg_101   \n",
       "...                     ...                           ...   \n",
       "50060  BraTS20_Training_369   BraTS20_Training_369_seg_95   \n",
       "50061  BraTS20_Training_369   BraTS20_Training_369_seg_96   \n",
       "50062  BraTS20_Training_369   BraTS20_Training_369_seg_97   \n",
       "50063  BraTS20_Training_369   BraTS20_Training_369_seg_98   \n",
       "50064  BraTS20_Training_369   BraTS20_Training_369_seg_99   \n",
       "\n",
       "                                              image_path label_flair label_t1  \\\n",
       "0      /home/shsingh/knowledge_distillation/dataset/s...     discard  discard   \n",
       "1      /home/shsingh/knowledge_distillation/dataset/s...     discard  discard   \n",
       "2      /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "3      /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "4      /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "...                                                  ...         ...      ...   \n",
       "50060  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "50061  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "50062  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "50063  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "50064  /home/shsingh/knowledge_distillation/dataset/s...         HGG      HGG   \n",
       "\n",
       "      label_t1ce label_t2  \n",
       "0        discard  discard  \n",
       "1        discard  discard  \n",
       "2        healthy  healthy  \n",
       "3            HGG      HGG  \n",
       "4            HGG      HGG  \n",
       "...          ...      ...  \n",
       "50060        HGG      HGG  \n",
       "50061        HGG      HGG  \n",
       "50062        HGG      HGG  \n",
       "50063        HGG      HGG  \n",
       "50064        HGG      HGG  \n",
       "\n",
       "[50065 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/train_test_splits/train_df.csv',index_col =0)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4d629a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_weight.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0c26b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['healthy', 'HGG', 'LGG']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.64073164, 0.82428511, 4.42259248])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_class_weight = train_df[train_df['label_flair']!='discard']\n",
    "df_class_weight = df_class_weight.fillna('healthy')\n",
    "\n",
    "classes_list = df_class_weight['label_flair'].unique().tolist()\n",
    "print(classes_list)\n",
    "label_col =  df_class_weight['label_flair']\n",
    "\n",
    "class_weights = compute_class_weight('balanced',classes =  classes_list, y = label_col)\n",
    "class_weights\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e987019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64073164, 0.82428511, 4.42259248])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights =compute_class_weight(class_weight = \"balanced\",\n",
    "                        classes = df_class_weight['label_flair'].unique().tolist(),\n",
    "                        y = df_class_weight['label_flair'])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81828f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'healthy': 0.6407316407316407,\n",
       " 'HGG': 0.8242851069335847,\n",
       " 'LGG': 4.422592482396112}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = dict(zip(df_class_weight['label_flair'].unique().tolist(), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663df001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = df[df[subject_id_column_name].isin(train_subjects_other)].reset_index(drop=True)\n",
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00f9ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "healthy    23154\n",
       "HGG        18033\n",
       "discard     5472\n",
       "LGG         3361\n",
       "Name: label_flair, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label_flair'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee200315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_idx(label):\n",
    "    idx = 0\n",
    "    if label == 'discard':idx =4\n",
    "    if label == 'healthy':idx =0\n",
    "    if label == 'HGG':idx =1\n",
    "    if label=='LGG': idx = 2        \n",
    "    return idx\n",
    "\n",
    "\n",
    "def get_metadata_csv_label_encoded(meta_data_df):\n",
    "    \"\"\"Load meta csv. Filter samples to be discarded and label encoding.\"\"\"\n",
    "    meta_data = meta_data_df.copy()\n",
    "    meta_data['label_flair'] = meta_data['label_flair'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t1'] = meta_data['label_t1'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t1ce'] = meta_data['label_t1ce'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t2'] = meta_data['label_t2'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data_df  = meta_data.reset_index(drop =True)\n",
    "    return meta_data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_metadata_csv_label_encoded(train_df)\n",
    "train_df['patient_id'] = train_df['subject_id'].str[-3:].astype(int)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0b08dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>image_idx</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_flair</th>\n",
       "      <th>label_t1</th>\n",
       "      <th>label_t1ce</th>\n",
       "      <th>label_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>BraTS20_Training_032</td>\n",
       "      <td>BraTS20_Training_032_seg_142</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18652</th>\n",
       "      <td>BraTS20_Training_131</td>\n",
       "      <td>BraTS20_Training_131_seg_145</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19176</th>\n",
       "      <td>BraTS20_Training_134</td>\n",
       "      <td>BraTS20_Training_134_seg_6</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19187</th>\n",
       "      <td>BraTS20_Training_134</td>\n",
       "      <td>BraTS20_Training_134_seg_7</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19220</th>\n",
       "      <td>BraTS20_Training_135</td>\n",
       "      <td>BraTS20_Training_135_seg_0</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47785</th>\n",
       "      <td>BraTS20_Training_354</td>\n",
       "      <td>BraTS20_Training_354_seg_139</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47944</th>\n",
       "      <td>BraTS20_Training_355</td>\n",
       "      <td>BraTS20_Training_355_seg_142</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48254</th>\n",
       "      <td>BraTS20_Training_357</td>\n",
       "      <td>BraTS20_Training_357_seg_142</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48593</th>\n",
       "      <td>BraTS20_Training_359</td>\n",
       "      <td>BraTS20_Training_359_seg_3</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48604</th>\n",
       "      <td>BraTS20_Training_359</td>\n",
       "      <td>BraTS20_Training_359_seg_4</td>\n",
       "      <td>/home/shsingh/knowledge_distillation/dataset/s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 subject_id                     image_idx  \\\n",
       "4699   BraTS20_Training_032  BraTS20_Training_032_seg_142   \n",
       "18652  BraTS20_Training_131  BraTS20_Training_131_seg_145   \n",
       "19176  BraTS20_Training_134    BraTS20_Training_134_seg_6   \n",
       "19187  BraTS20_Training_134    BraTS20_Training_134_seg_7   \n",
       "19220  BraTS20_Training_135    BraTS20_Training_135_seg_0   \n",
       "...                     ...                           ...   \n",
       "47785  BraTS20_Training_354  BraTS20_Training_354_seg_139   \n",
       "47944  BraTS20_Training_355  BraTS20_Training_355_seg_142   \n",
       "48254  BraTS20_Training_357  BraTS20_Training_357_seg_142   \n",
       "48593  BraTS20_Training_359    BraTS20_Training_359_seg_3   \n",
       "48604  BraTS20_Training_359    BraTS20_Training_359_seg_4   \n",
       "\n",
       "                                              image_path label_flair label_t1  \\\n",
       "4699   /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "18652  /home/shsingh/knowledge_distillation/dataset/s...         NaN  healthy   \n",
       "19176  /home/shsingh/knowledge_distillation/dataset/s...     healthy      NaN   \n",
       "19187  /home/shsingh/knowledge_distillation/dataset/s...     healthy      NaN   \n",
       "19220  /home/shsingh/knowledge_distillation/dataset/s...     healthy      NaN   \n",
       "...                                                  ...         ...      ...   \n",
       "47785  /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "47944  /home/shsingh/knowledge_distillation/dataset/s...         NaN  healthy   \n",
       "48254  /home/shsingh/knowledge_distillation/dataset/s...     healthy  healthy   \n",
       "48593  /home/shsingh/knowledge_distillation/dataset/s...         NaN  healthy   \n",
       "48604  /home/shsingh/knowledge_distillation/dataset/s...         NaN  healthy   \n",
       "\n",
       "      label_t1ce label_t2  \n",
       "4699     healthy      NaN  \n",
       "18652    healthy  healthy  \n",
       "19176    healthy      NaN  \n",
       "19187    healthy      NaN  \n",
       "19220    healthy      NaN  \n",
       "...          ...      ...  \n",
       "47785    healthy      NaN  \n",
       "47944    healthy  healthy  \n",
       "48254        NaN  healthy  \n",
       "48593    healthy  healthy  \n",
       "48604    healthy  healthy  \n",
       "\n",
       "[132 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = train_df[train_df.isna().any(axis=1)]\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb36e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['label_flair']  = train_df['label_flair'].fillna('discard')\n",
    "train_df= train_df.fillna('healthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ffc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find NaN values\n",
    "nan_locations = train_df.isna()\n",
    "\n",
    "# Count NaN values per column\n",
    "nan_counts = train_df.isna().sum()\n",
    "\n",
    "print(\"NaN Locations:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'subject_id' is the column you want to use for grouping\n",
    "# Assuming 'target' is the column representing the classes\n",
    "\n",
    "# Define the number of splits\n",
    "n_splits = 3\n",
    "\n",
    "# Initialize StratifiedGroupKFold\n",
    "sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Extract features and target\n",
    "# X = train_df['image_idx'] # Adjust 'target' with the actual column name\n",
    "X = train_df\n",
    "y = train_df['label_flair']\n",
    "\n",
    "# Define the groups (subject_id in your case)\n",
    "# groups = np.unique(train_df['subject_id'])\n",
    "groups = train_df['patient_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6341b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f282f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_column_name = 'label_flair'\n",
    "subject_id_column_name = 'subject_id'\n",
    "\n",
    "healthy = 'healthy'\n",
    "discard = 'discard'\n",
    "test_size = 0.3\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c641bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "def create_StratifiedGroupKFold_splits(k, train_df,\n",
    "                                        subject_id_column_name,\n",
    "                                        class_column_name): \n",
    "    train_df= train_df.fillna('healthy')\n",
    "    train_df_encoded = get_metadata_csv_label_encoded(train_df)\n",
    "    train_df_encoded['patient_id'] = train_df_encoded[subject_id_column_name].str[-3:].astype(int)\n",
    "    \n",
    "    kfold_dict = {f\"train_{i}\": [] for i in range(k)}\n",
    "    kfold_dict.update({f\"val_{i}\": [] for i in range(k)})\n",
    "    \n",
    "    kfold_dist_dict = {f\"train_{i}\": [] for i in range(k)}\n",
    "    kfold_dist_dict.update({f\"val_{i}\": [] for i in range(k)})\n",
    "\n",
    "    n_splits = k\n",
    "    # Initialize StratifiedGroupKFold\n",
    "    sgkf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    # Extract features and target\n",
    "    X = train_df_encoded\n",
    "    y = train_df_encoded[class_column_name]\n",
    "    # Define the groups (subject_id in your case)\n",
    "    groups = train_df_encoded['patient_id']\n",
    "    \n",
    "    \n",
    "    # Iterate through the splits\n",
    "    for i, (train_index, val_idx) in enumerate(sgkf.split(X, y,groups)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        # Ensure that the validation set is balanced\n",
    "        unique_classes, class_counts = np.unique(y[val_idx], return_counts=True)\n",
    "        print('unique_classes:', unique_classes)\n",
    "        min_class_count = min(class_counts)\n",
    "\n",
    "        balanced_val_indices = []\n",
    "        for cls in unique_classes:\n",
    "            cls_indices = val_idx[y[val_idx] == cls]\n",
    "            balanced_val_indices.extend(cls_indices[:min_class_count])\n",
    "\n",
    "        kfold_dict[f'val_{i}'].extend(balanced_val_indices)\n",
    "        kfold_dict[f'train_{i}'].extend(train_index)\n",
    "\n",
    "        kfold_dist_dict[f'val_{i}'] = dict(y[balanced_val_indices].value_counts())\n",
    "        kfold_dist_dict[f'train_{i}'] = dict(y[train_index].value_counts())\n",
    "        # If you want to see the class distribution in each fold\n",
    "        print(f'Fold {len(train_index)} Class Distribution:')\n",
    "        print(y[balanced_val_indices].value_counts())\n",
    "    return kfold_dict, kfold_dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13c326ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "unique_classes: [0 1 2 4]\n",
      "Fold 33325 Class Distribution:\n",
      "0    1125\n",
      "1    1125\n",
      "2    1125\n",
      "4    1125\n",
      "Name: label_flair, dtype: int64\n",
      "Fold 1:\n",
      "unique_classes: [0 1 2 4]\n",
      "Fold 33325 Class Distribution:\n",
      "0    1095\n",
      "1    1095\n",
      "2    1095\n",
      "4    1095\n",
      "Name: label_flair, dtype: int64\n",
      "Fold 2:\n",
      "unique_classes: [0 1 2 4]\n",
      "Fold 33480 Class Distribution:\n",
      "0    1141\n",
      "1    1141\n",
      "2    1141\n",
      "4    1141\n",
      "Name: label_flair, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold_dict, kfold_dist_dict = create_StratifiedGroupKFold_splits(k, train_df,\n",
    "                                        subject_id_column_name,\n",
    "                                        class_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f07a290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_0': {0: 15421, 1: 12005, 4: 3663, 2: 2236},\n",
       " 'train_1': {0: 15493, 1: 11929, 4: 3637, 2: 2266},\n",
       " 'train_2': {0: 15484, 1: 12132, 4: 3644, 2: 2220},\n",
       " 'val_0': {0: 1125, 1: 1125, 2: 1125, 4: 1125},\n",
       " 'val_1': {0: 1095, 1: 1095, 2: 1095, 4: 1095},\n",
       " 'val_2': {0: 1141, 1: 1141, 2: 1141, 4: 1141}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ff947",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kfold_dict['train_0']),len(kfold_dict['train_1']),len(kfold_dict['train_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4edc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store train and validation indices\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "\n",
    "\n",
    "# Iterate through the splits\n",
    "for train_idx, val_idx in sgkf.split(X, y, groups=groups):\n",
    "    # Ensure that the validation set is balanced\n",
    "    unique_classes, class_counts = np.unique(y[val_idx], return_counts=True)\n",
    "    print(class_counts)\n",
    "    print(unique_classes)\n",
    "    break\n",
    "    min_class_count = min(class_counts)\n",
    "\n",
    "    balanced_val_indices = []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = val_idx[y[val_idx] == cls]\n",
    "        balanced_val_indices.extend(cls_indices[:min_class_count])\n",
    "\n",
    "    train_indices.append(train_idx)\n",
    "    val_indices.append(balanced_val_indices)\n",
    "\n",
    "    # If you want to see the class distribution in each fold\n",
    "    print(f'Fold {len(train_indices)} Class Distribution:')\n",
    "    print(y[balanced_val_indices].value_counts())\n",
    "#     print(balanced_val_indices)\n",
    "    \n",
    "#     train_fold_df = df[df[subject_id_column_name].isin(train_idx)].reset_index(drop=True)\n",
    "#     val_fold_df = df[df[subject_id_column_name].isin(balanced_val_indices)].reset_index(drop=True)\n",
    "    val_fold_df = df.loc[balanced_val_indices].reset_index(drop=True)\n",
    "    train_fold_df = df.loc[train_idx].reset_index(drop=True)\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df434a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_fold_df['subject_id']), len(val_fold_df['subject_id'])\n",
    "print(dict( y[balanced_val_indices].value_counts()))\n",
    "print(dict( y[train_idx].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa850c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_df[train_fold_df['subject_id']== 'BraTS20_Training_212']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec23797",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(groups[balanced_val_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(groups[balanced_val_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfa7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fold_df.groupby(['subject_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fold_df['label_flair'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bdf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_df['label_flair'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcaa734",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_df['label_flair'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_fold_df[val_fold_df['label_flair'] == 'LGG']['subject_id'].value_counts()))\n",
    "val_fold_df[val_fold_df['label_flair'] == 'LGG']['subject_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e662aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_fold_df[train_fold_df['label_flair'] == 'LGG']['subject_id'].value_counts()))\n",
    "train_fold_df[train_fold_df['label_flair'] == 'LGG']['subject_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0774012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_class(idx):\n",
    "    \n",
    "    if idx == 4:label='discard'\n",
    "    if idx == 0:label='healthy'\n",
    "    if idx == 1:label='HGG'\n",
    "    if idx == 2:label='LGG'      \n",
    "    return label\n",
    "\n",
    "train_fold_df['label_flair'] = train_fold_df['label_flair'].apply(lambda x: idx_to_class(x))\n",
    "val_fold_df['label_flair'] = val_fold_df['label_flair'].apply(lambda x: idx_to_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db881732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_df = train_fold_df[train_fold_df.label_flair != 'discard']\n",
    "val_fold_df = val_fold_df[val_fold_df.label_flair != 'discard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4847a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8903f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f162b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(set(subject_id_class) - set(test_subjects))\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_subject = max(df_meta.groupby(['subject_id'])['label_flair'].count())#155\n",
    "df = df_meta.copy()\n",
    "\n",
    "mystring = 'healthy'\n",
    "discard = 'discard'\n",
    "test_size = 0.3\n",
    "\n",
    "minority_samples = min(class_dict.values())\n",
    "# min_samples\n",
    "min_test_samples = test_size* minority_samples\n",
    "print(int(np.round(min_test_samples)))\n",
    "\n",
    "minorty_class = [key for key in class_dict if class_dict[key] == min_test_samples]\n",
    "minorty_class\n",
    "\n",
    "for key in class_dict:\n",
    "    if key!= mystring and key!= discard:\n",
    "        print(key)\n",
    "        df_class =  df[df[class_column_name] == key]\n",
    "        subject_id_class =  np.unique(df_class[subject_id_column_name]).tolist()\n",
    "        print(key, f':{len(subject_id_class)}')\n",
    "        \n",
    "        train_subjects, test_subjects = train_test_split(subject_id_class ,\n",
    "                                            test_size = test_size, \n",
    "                                            random_state = 42, \n",
    "                                            shuffle = True) \n",
    "        training_subjects_list.extend(train_subjects)\n",
    "        test_subjects_list.extend(test_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de64480",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects_list=[]\n",
    "test_subjects_list =[]\n",
    "\n",
    "# class_dict = get_class_label_dict(df, class_column)\n",
    "\n",
    "for key in class_dict:\n",
    "    if key != class_healthy_name:\n",
    "        df_class =  df[df[class_column] == key]\n",
    "        subject_id_class =  np.unique(df_class[subject_id_column_name]).tolist()\n",
    "        train_subjects, test_subjects = train_test_split(subject_id_class ,\n",
    "                                            test_size = test_size, \n",
    "                                            random_state = 42, \n",
    "                                            shuffle = True) \n",
    "        training_subjects_list.extend(train_subjects)\n",
    "        test_subjects_list.extend(test_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa055f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88de793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a16db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/splits/train_df.csv', index_col=0)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48385aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Brats20ID']\n",
    "del train_df['Age']\n",
    "del train_df['Survival_days']\n",
    "del train_df['Extent_of_Resection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e782e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ca5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/splits/test_df.csv', index_col=0)\n",
    "del test_df['Brats20ID']\n",
    "del test_df['Age']\n",
    "del test_df['Survival_days']\n",
    "del test_df['Extent_of_Resection']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HGG:', len(np.unique(test_df[test_df[class_column_name]=='HGG']['subject_id'])))\n",
    "print('LGG:', len(np.unique(test_df[test_df[class_column_name]=='LGG']['subject_id'])))\n",
    "print('healthy:', len(np.unique(test_df[test_df[class_column_name]=='healthy']['subject_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df[class_column_name]=='healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df[class_column_name]=='HGG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbefd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df[class_column_name]=='LGG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c67ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829295bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_csv_path = '/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/meta_data_survival_mapping.csv'\n",
    "class_column_name = 'label_flair'\n",
    "subject_id_column_name = 'subject_id'\n",
    "csv_save_path = Path('/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/splits')\n",
    "test_size = 0.25\n",
    "class_healthy_name ='healthy'\n",
    "\n",
    "split = True  \n",
    "# test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_after_discard(csv_path):\n",
    "    \"\"\"Load meta csv. Filter samples to be discarded.\"\"\"\n",
    "    meta_data = pd.read_csv(csv_path)\n",
    "    meta_data = meta_data[meta_data.label_flair != 'discard']\n",
    "    meta_data = meta_data[meta_data.label_t1 != 'discard']\n",
    "    meta_data = meta_data[meta_data.label_t1ce != 'discard']\n",
    "    meta_data = meta_data[meta_data.label_t2 != 'discard']\n",
    "    meta_data_df  = meta_data.reset_index(drop =True)\n",
    "    return meta_data_df\n",
    "\n",
    "df = get_csv_after_discard(meta_csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e6b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['label_flair']=='LGG']['subject_id'].value_counts())\n",
    "print('HGG:', len(np.unique(df[df[class_column_name]=='HGG']['subject_id'])))\n",
    "print('LGG:', len(np.unique(df[df[class_column_name]=='LGG']['subject_id'])))\n",
    "print('healthy:', len(np.unique(df[df[class_column_name]=='healthy']['subject_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_label_dict(df, class_column):\n",
    "    class_dict = df[class_column].value_counts().to_dict()\n",
    "    return class_dict\n",
    "\n",
    "class_dict = get_class_label_dict(df, class_column_name)\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['subject_id']).value_counts(['label_flair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462b3d0",
   "metadata": {},
   "source": [
    "# Create balanced Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects_list=[]\n",
    "test_subjects_list =[]\n",
    "\n",
    "class_dict = get_class_label_dict(df, class_column)\n",
    "\n",
    "for key in class_dict:\n",
    "    if key != class_healthy_name:\n",
    "        df_class =  df[df[class_column] == key]\n",
    "        subject_id_class =  np.unique(df_class[subject_id_column_name]).tolist()\n",
    "        train_subjects, test_subjects = train_test_split(subject_id_class ,\n",
    "                                            test_size = test_size, \n",
    "                                            random_state = 42, \n",
    "                                            shuffle = True) \n",
    "        training_subjects_list.extend(train_subjects)\n",
    "        test_subjects_list.extend(test_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb07ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f16a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ec9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f782d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_to_idx(label):\n",
    "    idx = 0\n",
    "    if label == 'discard':idx =4\n",
    "    if label == 'healthy':idx =0\n",
    "    if label == 'HGG':idx =1\n",
    "    if label=='LGG': idx = 2        \n",
    "    return idx\n",
    "\n",
    "\n",
    "def get_class_label_dict(df, class_column):\n",
    "    class_dict = df[class_column].value_counts().to_dict()\n",
    "    return class_dict\n",
    "\n",
    "\n",
    "def get_csv_after_discard(csv_path):\n",
    "    \"\"\"Load meta csv. Filter samples to be discarded.\"\"\"\n",
    "    meta_data = pd.read_csv(csv_path)\n",
    "    meta_data = meta_data[meta_data.label_flair != 'discard']\n",
    "    meta_data = meta_data[meta_data.label_t1 != 'discard']\n",
    "    meta_data = meta_data[meta_data.label_t1ce != 'discard']\n",
    "    meta_data = meta_data[meta_data.label_t2 != 'discard']\n",
    "    meta_data_df  = meta_data.reset_index(drop =True)\n",
    "    return meta_data_df\n",
    "\n",
    "\n",
    "\n",
    "def get_metadata_csv_label_encoded(meta_data_df):\n",
    "    \"\"\"Load meta csv. Filter samples to be discarded and label encoding.\"\"\"\n",
    "    meta_data = meta_data_df.copy()\n",
    "    meta_data['label_flair'] = meta_data['label_flair'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t1'] = meta_data['label_t1'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t1ce'] = meta_data['label_t1ce'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data['label_t2'] = meta_data['label_t2'].apply(lambda x: class_to_idx(x))\n",
    "    meta_data_df  = meta_data.reset_index(drop =True)\n",
    "    return meta_data_df\n",
    "\n",
    "def generate_subject_id_splits(df, \n",
    "                             class_column, \n",
    "                             test_size,\n",
    "                             subject_id_column_name,\n",
    "                             class_healthy_name):\n",
    "    training_subjects_list=[]\n",
    "    test_subjects_list =[]\n",
    "    class_dict = get_class_label_dict(df, class_column)\n",
    "    for key in class_dict:\n",
    "        if key != class_healthy_name:\n",
    "            df_class =  df[df[class_column] == key]\n",
    "            subject_id_class =  np.unique(df_class[subject_id_column_name]).tolist()\n",
    "            train_subjects, test_subjects = train_test_split(subject_id_class ,\n",
    "                                                test_size = test_size, \n",
    "                                                random_state = 42, \n",
    "                                                shuffle = True) \n",
    "            training_subjects_list.extend(train_subjects)\n",
    "            test_subjects_list.extend(test_subjects)\n",
    "    return training_subjects_list, test_subjects_list\n",
    "\n",
    "\n",
    "def create_and_save_split(meta_csv_path , \n",
    "                         class_column,\n",
    "                         test_size,\n",
    "                         subject_id_column_name,\n",
    "                         class_healthy_name,\n",
    "                         csv_save_path):\n",
    "#     df = pd.read_csv(meta_csv_path)\n",
    "    df = get_csv_after_discard(meta_csv_path)\n",
    "    training_subjects_list, test_subjects_list = generate_subject_id_splits(df,\n",
    "                                                                          class_column, \n",
    "                                                                          test_size, \n",
    "                                                                          subject_id_column_name, \n",
    "                                                                          class_healthy_name)\n",
    "    train_df = df[df[subject_id_column_name].isin(training_subjects_list)].reset_index(drop=True)\n",
    "    test_df = df[df[subject_id_column_name].isin(test_subjects_list)].reset_index(drop=True)\n",
    "    \n",
    "    train_df.to_csv(csv_save_path / 'train_df.csv')\n",
    "    test_df.to_csv(csv_save_path / 'test_df.csv')\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def load_train_test_csv(csv_path):\n",
    "    if  os.path.exists(csv_path  / 'train_df.csv'):\n",
    "        train_df = pd.read_csv(csv_save_path / 'train_df.csv', index_col=0)\n",
    "        test_df = pd.read_csv(csv_save_path / 'test_df.csv', index_col=0)          \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def preprocess_train_df(train_df, subject_id_column_name):\n",
    "    train_df = train_df.fillna(0)\n",
    "    train_df = get_metadata_csv_label_encoded(train_df)\n",
    "    train_df.set_index(subject_id_column_name, inplace=True, drop=False)\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if split:\n",
    "    train_df, test_df = load_train_test_csv(csv_save_path)\n",
    "else:\n",
    "    train_df, test_df =  create_and_save_split(meta_csv_path , \n",
    "                                         class_column_name,\n",
    "                                         test_size,\n",
    "                                         subject_id_column_name,\n",
    "                                         class_healthy_name,\n",
    "                                         csv_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StratifiedGroupKFold\n",
    "train_df_processed =  preprocess_train_df(train_df, subject_id_column_name)\n",
    "train_df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.unique(train_df_processed[subject_id_column_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06112403",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_df[subject_id_column_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73975872",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b63ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = get_class_label_dict(train_df, class_column_name)\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2966286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict_test = get_class_label_dict(test_df, class_column_name)\n",
    "print(class_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(train_df[subject_id_column_name]).tolist()), len(np.unique(test_df[subject_id_column_name]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_subjects_list=[]\n",
    "test_subjects_list =[]\n",
    "\n",
    "training_subjects_list.extend(np.unique(train_df[subject_id_column_name]).tolist())\n",
    "test_subjects_list.extend(np.unique(test_df[subject_id_column_name]).tolist())\n",
    "\n",
    "result_split = any(item in test_subjects_list for item in training_subjects_list)\n",
    "result_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b47505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_overlapping_split(train_df, test_df):\n",
    "    \n",
    "    training_subjects_list=[]\n",
    "    test_subjects_list =[]\n",
    "\n",
    "    training_subjects_list.extend(np.unique(train_df[subject_id_column_name]).tolist())\n",
    "    test_subjects_list.extend(np.unique(test_df[subject_id_column_name]).tolist())\n",
    "\n",
    "    result_split = any(item in test_subjects_list for item in training_subjects_list)\n",
    "    print(result_split)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd332d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed512d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ca6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dddec6d5",
   "metadata": {},
   "source": [
    "# Load train_df and meta_csv to split into  KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c77ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data_split(meta_csv_path, train_df, subject_id_column_name):\n",
    "    #read meta_data_csv with 'discard' as well\n",
    "    df_meta = pd.read_csv(meta_csv_path)\n",
    "    #get the correct indexes (subject_id) from split train_df(as train & test splits also accounts the class distribution)\n",
    "    # use the only indexes from train_df to be considered from meta_data_csv\n",
    "    training_subjects_list =  np.unique(train_df[subject_id_column_name]).tolist()\n",
    "\n",
    "    train_df_indexed = df_meta[df_meta[subject_id_column_name].isin(training_subjects_list)].reset_index(drop=True)\n",
    "    return train_df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_indexed = prepare_train_data_split(meta_csv_path, train_df, subject_id_column_name)\n",
    "train_df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28178fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_df_indexed[subject_id_column_name].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a517f9b5",
   "metadata": {},
   "source": [
    "# GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c21a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold,  StratifiedKFold, StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_groupKFold_splits(df_indexed,class_column_name, subject_id_column_name,  k =3):\n",
    "    \n",
    "    kfold_dict = {f\"train_{i}\": [] for i in range(k)}\n",
    "    kfold_dict.update({f\"val_{i}\": [] for i in range(k)})\n",
    "    \n",
    "    df = df_indexed.copy()\n",
    "\n",
    "    X = df\n",
    "    y = df[class_column_name]\n",
    "    \n",
    "    groups = df[subject_id_column_name].values\n",
    "    group_kfold = GroupKFold(n_splits=3)\n",
    "    group_kfold.get_n_splits(X, y, groups)\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(group_kfold.split(X, y,groups)):        \n",
    "        print(f\"Fold {i}:\")\n",
    "        kfold_dict[f'train_{i}'].extend(groups[train_index])\n",
    "        kfold_dict[f'val_{i}'].extend(groups[val_index])\n",
    "        \n",
    "    return kfold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188630ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "kfold_dict =  create_groupKFold_splits(train_df_indexed,class_column_name, subject_id_column_name,  k)\n",
    "kfold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dcd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07000cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_indexed.set_index(subject_id_column_name, inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c531e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_using_kfold_indexes(df_indexed, class_column_name, subject_id_column_name, train_index, val_index):\n",
    "    \n",
    "    df = df_indexed.copy()\n",
    "#     train_df = df.iloc[train_index]\n",
    "#     val_df = df.iloc[val_index]\n",
    "    \n",
    "    train_df = df[df[subject_id_column_name].isin(train_index)].reset_index(drop=True)\n",
    "    val_df = df[df[subject_id_column_name].isin(val_index)].reset_index(drop=True)\n",
    "    \n",
    "    train_df[train_df[class_column_name]!='discard']\n",
    "    val_df[val_df[class_column_name]!='discard']\n",
    "    return train_df, val_df\n",
    "\n",
    "i =0\n",
    "if i<k:\n",
    "    for key in kfold_dict:        \n",
    "        train_index =  kfold_dict[f'train_{i}']\n",
    "        print(train_index)\n",
    "        val_index = kfold_dict[f'val_{i}']\n",
    "\n",
    "        train_df, val_df = get_df_using_kfold_indexes(train_df_indexed, class_column_name, 'subject_id', train_index, val_index)\n",
    "        break\n",
    "        train_df\n",
    "        # dataloader loop and continue to trainig\n",
    "    i=+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18540142",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i =0\n",
    "train_index =  kfold_dict[f'train_{i}']\n",
    "val_index = kfold_dict[f'val_{i}']\n",
    "\n",
    "# print('train_index:', train_index)\n",
    "# print('val_index:', val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(train_index)), len(np.unique(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiaze the model outside traini method:\n",
    "# model = get_model_by_name(model_name,num_classes, mod, device_index, to_use_pre_trained_weights )\n",
    "# device_index = f'cuda:{device_num}'\n",
    "\n",
    "\n",
    "def get_df_using_kfold_indexes(df_indexed, class_column_name, train_index, val_index):\n",
    "    \n",
    "    df = df_indexed.copy()\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[val_index]\n",
    "    \n",
    "    train_df[train_df[class_column_name]!='discard']\n",
    "    val_df[val_df[class_column_name]!='discard']\n",
    "    return train_df, val_df\n",
    "\n",
    "# def train_split_df_kfold_dict(df_indexed,class_column_name, kfold_dict, k):\n",
    "#     i =0\n",
    "#     if i<k:\n",
    "#         for key,value in kfold_dict:        \n",
    "#             train_index =  kfold_dict[f'train_{i}']\n",
    "#             val_index = kfold_dict[f'val_{i}']\n",
    "\n",
    "#             train_df, val_df = get_df_using_kfold_indexes(df_indexed, class_column_name, train_index, val_index)\n",
    "#             # dataloader loop and continue to trainig\n",
    "#         i=+1\n",
    "\n",
    "\n",
    "        \n",
    "def train_split_df_kfold_dict(df_indexed, class_column_name, kfold_dict, k, test_df):\n",
    "    fold =0\n",
    "    if fold < k:        \n",
    "        train_index =  kfold_dict[f'train_{i}']\n",
    "        val_index = kfold_dict[f'val_{i}']\n",
    "        train_df, val_df = get_df_using_kfold_indexes(df_indexed, \n",
    "                                                      class_column_name, \n",
    "                                                      train_index,\n",
    "                                                      val_index)\n",
    "        # dataloader loop and continue to trainig\n",
    "        if mod == 'flair_t1ce_t2':\n",
    "            train_dataloader, val_dataloader, test_dataloader =  get_multimodal_dataloader(train_df,\n",
    "                                                                                           test_df, \n",
    "                                                                                           val_df,\n",
    "                                                                                           batch_size)\n",
    "        else:\n",
    "            train_dataloader, val_dataloader, test_dataloader =  get_dataloader(train_df,\n",
    "                                                                                test_df,\n",
    "                                                                                val_df,\n",
    "                                                                                mod,\n",
    "                                                                                batch_size)\n",
    "        trained_model = start_train(model.to(device_index), train_dataloader, \n",
    "                                    val_dataloader,test_dataloader,\n",
    "                                    n_epochs , output_dir, \n",
    "                                    device_index, model_name, fold)\n",
    "        fold=+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfa56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label_flair'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_cruves(train_acc, val_acc, train_loss, val_loss, train_f1_scores, val_f1_scores, saving_dir, fold):    \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(f\"Train-Validation Accuracy_fold{fold}\")\n",
    "    plt.plot(train_acc, label='train')\n",
    "    plt.plot(val_acc, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('accuracy', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(saving_dir / f'fold{fold}' / f'training_acc_curve_fold{fold}.png',  bbox_inches='tight')\n",
    "    save_list_to_csv(train_acc, f'list_train_acc_fold{fold}', saving_dir / f'fold{fold}')\n",
    "    save_list_to_csv(val_acc, f'list_val_acc_fold{fold}', saving_dir /  f'fold{fold}')\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(f\"Train-Validation F1 score_fold{fold}\")\n",
    "    plt.plot(train_f1_scores, label='train')\n",
    "    plt.plot(val_f1_scores, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('f1 score', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(saving_dir / f'fold{fold}' / f'training_f1_curve_fold{fold}'.png',  bbox_inches='tight')\n",
    "    save_list_to_csv(train_f1_scores, f'list_train_f1_fold{fold}', saving_dir / f'fold{fold}')\n",
    "    save_list_to_csv(val_f1_scores, f'list_val_f1_fold{fold}', saving_dir / f'fold{fold}')\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(f\"Train-Validation Loss_fold{fold}\")\n",
    "    plt.plot(train_loss, label='train')\n",
    "    plt.plot(val_loss, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('loss', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(saving_dir / f'fold{fold}' / f'training_loss_curve_fold{fold}.png',  bbox_inches='tight')\n",
    "    save_list_to_csv(train_loss, f'list_train_loss_fold{fold}', saving_dir / f'fold{fold}')\n",
    "    save_list_to_csv(val_loss, f'list_val_loss_fold{fold}', saving_dir / f'fold{fold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(model, dataloader, saving_dir, device_index, fold):    \n",
    "    device = torch.device(device_index) if torch.cuda.is_available() else torch.device('cpu') \n",
    "    np.random.seed(31101995)\n",
    "    torch.manual_seed(31101995)\n",
    "    labels = ['healthy', 'HGG','LGG']\n",
    "    label_dict ={'0':'healthy', '1':'HGG','2':'LGG'}\n",
    "    y_pred_list = []\n",
    "    y_true_list = []    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_test_pred = model(x_batch)\n",
    "            _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
    "                        \n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "            y_true_list.append(y_batch.cpu().numpy())      \n",
    "    y_pred_list = [i[0] for i in y_pred_list]\n",
    "    y_true_list = [i[0] for i in y_true_list]\n",
    "\n",
    "    print(classification_report(y_true_list, y_pred_list))\n",
    "    classification_report_df = pd.DataFrame(classification_report(y_true_list, y_pred_list, output_dict=True))\n",
    "    classification_report_df.rename(columns=label_dict, inplace=True)\n",
    "    cm = confusion_matrix(y_true_list, y_pred_list)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    # Add numbers to the confusion matrix heatmap.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(x=j, y=i, s=cm[i, j], va='center', ha='center', color='white')\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(saving_dir / f'fold{fold}' / f'confusion_matrix_fold{fold}.png')\n",
    "    plt.show()\n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true_list, y_pred_list),index=labels)\n",
    "    confusion_matrix_df.to_csv( saving_dir / f'fold{fold}' / f'confusion_matrix_df_fold{fold}.csv',index=False )\n",
    "    classification_report_df.to_csv( saving_dir / f'fold{fold}' / f'classification_report_df_fold{fold}.csv',index=False )\n",
    "    return confusion_matrix_df, classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_csv = '/home/shsingh/knowledge_distillation/dataset/scratch/dataframes/splits/fold_0/train_df_fold_0.csv'\n",
    "fold0_df = pd.read_csv(fold0_csv)\n",
    "fold0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold0_df['subject_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d04082",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_df[fold0_df['subject_id']== 'BraTS20_Training_001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_eval_path ='/home/shsingh/knowledge_distillation/kfold_result/flair/baseline/densenet121/fold0/list_train_acc_fold0.csv'\n",
    "kfold_eval_train_acc  = pd.read_csv(kfold_eval_path)\n",
    "# kfold_eval_train_acc = kfold_eval_train_acc.T.reset_index()\n",
    "# kfold_eval_train_acc = kfold_eval_train_acc.rename(columns={\"index\": \"train_acc\"})\n",
    "\n",
    "# kfold_eval_train_acc['train_acc'] = kfold_eval_train_acc['train_acc'].round(3)\n",
    "kfold_eval_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef052cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f88d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = kfold_eval_train_acc.copy()\n",
    "df = pd.DataFrame(df_acc.T)\n",
    "df.reset_index(level=0, inplace=True)\n",
    "# Rename the column\n",
    "df = df.rename(columns={'index': 'accuracy'})\n",
    "# Convert the 'accuracy' column to numeric type\n",
    "df['accuracy'] = df['accuracy'].astype(str).str.replace(r'(\\d+\\.\\d+)\\.(\\d+)', r'\\1\\2')\n",
    "df['accuracy'] = pd.to_numeric(df['accuracy'], errors='coerce')\n",
    "# Round the 'accuracy' column to 4 decimal places\n",
    "df['accuracy'] = df['accuracy'].round(4)\n",
    "df = df.rename_axis('epoch')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( df['accuracy'])\n",
    "# Set plot title and labels\n",
    "plt.title('Accuracy vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7725732",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_eval_path_val ='/home/shsingh/knowledge_distillation/kfold_result/flair/baseline/densenet121/fold0/list_val_acc_fold0.csv'\n",
    "kfold_eval_val_acc  = pd.read_csv(kfold_eval_path_val)\n",
    "\n",
    "df_val = kfold_eval_val_acc.copy()\n",
    "dfff = pd.DataFrame(df_val.T)\n",
    "dfff.reset_index(level=0, inplace=True)\n",
    "# Rename the column\n",
    "dfff = dfff.rename(columns={'index': 'accuracy'})\n",
    "# Convert the 'accuracy' column to numeric type\n",
    "dfff['accuracy'] = dfff['accuracy'].astype(str).str.replace(r'(\\d+\\.\\d+)\\.(\\d+)', r'\\1\\2')\n",
    "dfff['accuracy'] = pd.to_numeric(dfff['accuracy'], errors='coerce')\n",
    "# Round the 'accuracy' column to 4 decimal places\n",
    "dfff['accuracy'] = dfff['accuracy'].round(4)\n",
    "dfff = dfff.rename_axis('epoch')\n",
    "\n",
    "\n",
    "plt.plot( dfff['accuracy'])\n",
    "# Set plot title and labels\n",
    "plt.title('Accuracy vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e59c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_loss_path ='/home/shsingh/knowledge_distillation/kfold_result/flair/baseline/efficientnet_v2_s/fold0/list_train_loss_fold0.csv'\n",
    "fold0_loss_df  = pd.read_csv(fold0_loss_path)\n",
    "\n",
    "# df_val = fold0_loss_df.copy()\n",
    "fold0_loss_df = pd.DataFrame(fold0_loss_df.T)\n",
    "fold0_loss_df.reset_index(level=0, inplace=True)\n",
    "# Rename the column\n",
    "fold0_loss_df = fold0_loss_df.rename(columns={'index': 'loss'})\n",
    "# Convert the 'accuracy' column to numeric type\n",
    "fold0_loss_df['loss'] = fold0_loss_df['loss'].astype(str).str.replace(r'(\\d+\\.\\d+)\\.(\\d+)', r'\\1\\2')\n",
    "fold0_loss_df['loss'] = pd.to_numeric(fold0_loss_df['loss'], errors='coerce')\n",
    "# Round the 'accuracy' column to 4 decimal places\n",
    "fold0_loss_df['loss'] = fold0_loss_df['loss'].round(4)\n",
    "fold0_loss_df = fold0_loss_df.rename_axis('epoch')\n",
    "\n",
    "\n",
    "plt.plot( fold0_loss_df['loss'])\n",
    "# Set plot title and labels\n",
    "plt.title('loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_result = Path('/home/shsingh/knowledge_distillation/kfold_result')\n",
    "mod = 'flair'\n",
    "model_type = 'baseline'\n",
    "model_name = 'densenet121'\n",
    "fold = 'fold0'\n",
    "metric = 'acc' #f1, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a11962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_plotting_df(df_metric, metric):    \n",
    "    df = pd.DataFrame(df_metric.T)\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    metric_col_name =  metric\n",
    "        \n",
    "    # Rename the column\n",
    "    df = df.rename(columns={'index': metric_col_name})\n",
    "    # Convert the 'accuracy' column to numeric type\n",
    "    df[metric_col_name] = df[metric_col_name].astype(str).str.replace(r'(\\d+\\.\\d+)\\.(\\d+)', r'\\1\\2')\n",
    "    df[metric_col_name] = pd.to_numeric(df[metric_col_name], errors='coerce')\n",
    "    # Round the 'accuracy' column to 4 decimal places\n",
    "    df[metric_col_name] = df[metric_col_name].round(4)\n",
    "        \n",
    "    df = df.rename_axis('epoch')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ff4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_trainig_plots(mod, model_type, model_name, fold, metric ):\n",
    "    \n",
    "    kfold_result = Path('/home/shsingh/knowledge_distillation/kfold_result')\n",
    "    fold_path =  kfold_result/ mod / model_type / model_name / fold \n",
    "    \n",
    "    train_csv_path =  fold_path / f'list_train_{metric}_{fold}.csv'\n",
    "    val_csv_path = fold_path / f'list_val_{metric}_{fold}.csv'\n",
    "    \n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    val_df = pd.read_csv(val_csv_path)\n",
    "\n",
    "    \n",
    "    if metric == 'acc':   \n",
    "        metric = 'accuracy'\n",
    "    else:\n",
    "        metric = metric\n",
    "        \n",
    "    \n",
    "    \n",
    "    train_df_plot = get_metric_plotting_df(train_df, metric)\n",
    "    val_df_plot = get_metric_plotting_df(val_df, metric)\n",
    "    \n",
    "    train_df_plot[metric] = train_df_plot[metric] / 10\n",
    "#     val_df_plot[metric] = val_df_plot[metric] / 100\n",
    "    \n",
    "    plt.plot(train_df_plot[metric], label='train')\n",
    "    plt.plot(val_df_plot[metric], label='validation')\n",
    "\n",
    "    # Set plot title and labels\n",
    "    plt.title(f'{metric} vs Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric)\n",
    "    # Add legend\n",
    "    plt.legend(['train', 'val'],loc='best')\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    return  train_df_plot, val_df_plot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dede00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mod = 'flair'\n",
    "model_type = 'baseline'\n",
    "model_name = 'densenet121'\n",
    "fold = 'fold0'\n",
    "metric = 'loss' #f1, loss\n",
    "\n",
    "train_df_plot, val_df_plot   = get_and_save_trainig_plots(mod, model_type, model_name, fold, metric )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96011296",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8531598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beef892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee6bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b0509c7",
   "metadata": {},
   "source": [
    "# DRAFT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b23401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groupKFold_splits(df,class_column_name, subject_id_column_name,  k =3):\n",
    "    \n",
    "    train_0 = []\n",
    "    train_1 = []\n",
    "    train_2 = []\n",
    "\n",
    "    val_0 = []\n",
    "    val_1 = []\n",
    "    val_2 = []\n",
    "    \n",
    "    X = df\n",
    "    y = df[class_column_name]\n",
    "    \n",
    "    groups = df[subject_id_column_name].values\n",
    "    group_kfold = GroupKFold(n_splits=3)\n",
    "    group_kfold.get_n_splits(X, y, groups)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(group_kfold.split(X, y,groups)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        if i == 0:\n",
    "            train_0.extend(groups[train_index])\n",
    "            val_0.extend(groups[test_index])\n",
    "        if i == 1:\n",
    "            train_1.extend(groups[train_index])\n",
    "            val_1.extend(groups[test_index])\n",
    "        if i == 2:\n",
    "            train_2.extend(groups[train_index])\n",
    "            val_2.extend(groups[test_index])\n",
    "\n",
    "        print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
    "        print(f\"  Test:  index={test_index}, group={groups[test_index]}\")\n",
    "        \n",
    "    print(any(item in np.unique(val_0) for item in np.unique(train_0)))\n",
    "    print(any(item in np.unique(val_1) for item in np.unique(train_1)))\n",
    "    print(any(item in np.unique(val_2) for item in np.unique(train_2)))\n",
    "    return  train_0, val_0, train_1, val_1, train_2, val_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0, val_0, train_1, val_1, train_2, val_2 = create_groupKFold_splits(train_df_indexed,\n",
    "                                                                          class_column_name,\n",
    "                                                                          subject_id_column_name,\n",
    "                                                                          k =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03180331",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.unique(train_0)), len(np.unique(val_0)) )\n",
    "\n",
    "any(item in np.unique(val_0) for item in np.unique(train_0))\n",
    "\n",
    "# np.unique(train_0.tolist()),np.unique(train_0.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_indexed[train_df_indexed['label_flair']!='discard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "for i in range(k):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5fed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22561c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kfold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dict = dict.fromkeys(fold_ids, [])\n",
    "kfold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f14a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dict = {f\"train_{i}\": [] for i in range(k)}\n",
    "kfold_dict.update({f\"val_{i}\": [] for i in range(k)})\n",
    "\n",
    "\n",
    "df = train_df_indexed.copy()\n",
    "\n",
    "X = df\n",
    "y = df[class_column_name]\n",
    "\n",
    "groups = df[subject_id_column_name].values\n",
    "group_kfold = GroupKFold(n_splits=3)\n",
    "group_kfold.get_n_splits(X, y, groups)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(group_kfold.split(X, y,groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    kfold_dict[f'train_{i}'].extend(groups[train_index])\n",
    "    kfold_dict[f'val_{i}'].extend(groups[val_index])\n",
    "#     if i == 0:\n",
    "#         train_0.extend(groups[train_index])\n",
    "#         val_0.extend(groups[test_index])\n",
    "#     if i == 1:\n",
    "#         train_1.extend(groups[train_index])\n",
    "#         val_1.extend(groups[test_index])\n",
    "#     if i == 2:\n",
    "#         train_2.extend(groups[train_index])\n",
    "#         val_2.extend(groups[test_index])\n",
    "\n",
    "    print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
    "    print(f\"  Test:  index={val_index}, group={groups[val_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dict\n",
    "for key, value in kfold_dict.items():\n",
    "    unique_values = set(value)\n",
    "    print(f\"Unique elements in {key}: {unique_values}\")\n",
    "    print('XXXXXXXXXXXXXXXXXXXXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d6bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cb75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4549d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_0 = []\n",
    "group_1 = []\n",
    "group_2 = []\n",
    "\n",
    "group_0_val = []\n",
    "group_1_val = []\n",
    "group_2_val = []\n",
    "\n",
    "X = df\n",
    "y = df[class_column_name]\n",
    "groups = df['subject_id'].values\n",
    "group_kfold = GroupKFold(n_splits=3)\n",
    "group_kfold.get_n_splits(X, y, groups)\n",
    "# print(groups)\n",
    "# print(group_kfold)\n",
    "for i, (train_index, test_index) in enumerate(group_kfold.split(X, y,groups)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    if i == 0:\n",
    "        group_0.extend(groups[train_index])\n",
    "        group_0_val.extend(groups[test_index])\n",
    "    if i == 1:\n",
    "        group_1.extend(groups[train_index])\n",
    "        group_1_val.extend(groups[test_index])\n",
    "    if i == 2:\n",
    "        group_2.extend(groups[train_index])\n",
    "        group_2_val.extend(groups[test_index])\n",
    "\n",
    "    print(f\"  Train: index={train_index}, group={groups[train_index]}\")\n",
    "#     print('train_group:',np.unique() )\n",
    "    print(f\"  Test:  index={test_index}, group={groups[test_index]}\")\n",
    "#     train_data = df.iloc[train_index]\n",
    "#     val_data = df.iloc[test_index]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b690b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_overlappin_splits():\n",
    "    print(any(item in np.unique(group_0_val) for item in np.unique(group_0)))\n",
    "    print(any(item in np.unique(group_1_val) for item in np.unique(group_1)))\n",
    "    print(any(item in np.unique(group_2_val) for item in np.unique(group_2))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627b048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dba752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884f1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lis = np.unique(train_data['subject_id'])\n",
    "test_lis = np.unique(val_data['subject_id'])\n",
    "\n",
    "any(item in test_lis for item in train_lis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(any(item in np.unique(group_0_val) for item in np.unique(group_0)))\n",
    "print(any(item in np.unique(group_1_val) for item in np.unique(group_1)))\n",
    "print(any(item in np.unique(group_2_val) for item in np.unique(group_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(any(item in np.unique(group_0_val) for item in np.unique(group_1_val)))\n",
    "print(any(item in np.unique(group_1_val) for item in np.unique(group_2_val)))\n",
    "print(any(item in np.unique(group_2_val) for item in np.unique(group_0_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5657da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(any(item in np.unique(group_0_val) for item in np.unique(group_1_val)))\n",
    "print(any(item in np.unique(group_1_val) for item in np.unique(group_2_val)))\n",
    "print(any(item in np.unique(group_2_val) for item in np.unique(group_0_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134336d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a948bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ec2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9707b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f437f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb85742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d53f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b9214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99e27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26109d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a101d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac074c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bc5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f271862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4113e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573384b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb8dbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b81468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ddec13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce60dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
